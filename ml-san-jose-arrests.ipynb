{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mplcyberpunk\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "# ML Modeling\n",
    "from sklearn.metrics import precision_recall_fscore_support,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import RocCurveDisplay,roc_curve\n",
    "from sklearn.preprocessing import normalize\n",
    "# Saving and importing trained models\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read through Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rj/l_96jjr56y39j9jw2hnmv_wh0000gn/T/ipykernel_5088/1538011803.py:1: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/processed-dataset.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrest_unique_id</th>\n",
       "      <th>incident_number</th>\n",
       "      <th>pin</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>arrest_date</th>\n",
       "      <th>arrest_time</th>\n",
       "      <th>location_of_arrest_in_block</th>\n",
       "      <th>arrest_reason</th>\n",
       "      <th>arrest_type</th>\n",
       "      <th>summary_of_facts</th>\n",
       "      <th>arrest_officer</th>\n",
       "      <th>officer_name</th>\n",
       "      <th>current_status</th>\n",
       "      <th>young_offender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56511</th>\n",
       "      <td>SJ201519</td>\n",
       "      <td>SJ2015150010241</td>\n",
       "      <td>441762891</td>\n",
       "      <td>19.0</td>\n",
       "      <td>M</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>415.0</td>\n",
       "      <td>2900 BLOCK OCALA CT</td>\n",
       "      <td>CRIMINAL CITATION</td>\n",
       "      <td>TAKEN INTO CUSTODY/WARRANT ARREST ONLY</td>\n",
       "      <td>TRESPASSING (CITE)</td>\n",
       "      <td>4222</td>\n",
       "      <td>MACIAS</td>\n",
       "      <td>CITED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56522</th>\n",
       "      <td>SJ201519</td>\n",
       "      <td>SJ2015J3347648 C</td>\n",
       "      <td>441762891</td>\n",
       "      <td>19.0</td>\n",
       "      <td>M</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>415.0</td>\n",
       "      <td>2900 BLOCK OCALA CT</td>\n",
       "      <td>CRIMINAL CITATION</td>\n",
       "      <td>TAKEN INTO CUSTODY/WARRANT ARREST ONLY</td>\n",
       "      <td>TRESPASSING (CITE)</td>\n",
       "      <td>4222</td>\n",
       "      <td>MACIAS</td>\n",
       "      <td>CITED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51970</th>\n",
       "      <td>SJ20157</td>\n",
       "      <td>SJ2015150010272</td>\n",
       "      <td>441776037</td>\n",
       "      <td>23.0</td>\n",
       "      <td>F</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>530.0</td>\n",
       "      <td>5100 BLOCK MONTEREY RD</td>\n",
       "      <td>ON VIEW</td>\n",
       "      <td>ON VIEW ARREST</td>\n",
       "      <td>INFLICT CORP INJ ON SPOUSE/COHAB (ONVW)</td>\n",
       "      <td>4348</td>\n",
       "      <td>LEE</td>\n",
       "      <td>CHARGED/BOOKED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94333</th>\n",
       "      <td>SJ2015190</td>\n",
       "      <td>SJ2015150010482</td>\n",
       "      <td>441915772</td>\n",
       "      <td>33.0</td>\n",
       "      <td>F</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2200 BLOCK TULLY RD</td>\n",
       "      <td>CRIMINAL CITATION</td>\n",
       "      <td>TAKEN INTO CUSTODY/WARRANT ARREST ONLY</td>\n",
       "      <td>PETTY THEFT OF PERSONAL PROPERTY/LABOR/EMBEZZL...</td>\n",
       "      <td>3153</td>\n",
       "      <td>TOMPKINS</td>\n",
       "      <td>CITED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94339</th>\n",
       "      <td>SJ2015190</td>\n",
       "      <td>SJ2015J3337366 C</td>\n",
       "      <td>441915772</td>\n",
       "      <td>33.0</td>\n",
       "      <td>F</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2200 BLOCK TULLY RD</td>\n",
       "      <td>CRIMINAL CITATION</td>\n",
       "      <td>TAKEN INTO CUSTODY/WARRANT ARREST ONLY</td>\n",
       "      <td>PETTY THEFT OF PERSONAL PROPERTY/LABOR/EMBEZZL...</td>\n",
       "      <td>3153</td>\n",
       "      <td>TOMPKINS</td>\n",
       "      <td>CITED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>SJ2015337</td>\n",
       "      <td>SJ2015J3354478 C</td>\n",
       "      <td>441916123</td>\n",
       "      <td>23.0</td>\n",
       "      <td>M</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>CURTNER AV / 87</td>\n",
       "      <td>CRIMINAL CITATION</td>\n",
       "      <td>TAKEN INTO CUSTODY/WARRANT ARREST ONLY</td>\n",
       "      <td>FAILING TO PROVIDE EVIDENCE OF FINANCIAL RESPO...</td>\n",
       "      <td>4280</td>\n",
       "      <td>ARANA</td>\n",
       "      <td>CITED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96726</th>\n",
       "      <td>SJ201529</td>\n",
       "      <td>SJ2015150010655</td>\n",
       "      <td>441915179</td>\n",
       "      <td>22.0</td>\n",
       "      <td>M</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>1655.0</td>\n",
       "      <td>S 1ST ST / W ALMA AV</td>\n",
       "      <td>ON VIEW</td>\n",
       "      <td>ON VIEW ARREST</td>\n",
       "      <td>RESISTING, DELAYING, OBSTRUCTING AN OFFICER (O...</td>\n",
       "      <td>4245</td>\n",
       "      <td>VALOSEK</td>\n",
       "      <td>CHARGED/BOOKED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14755</th>\n",
       "      <td>SJ201525</td>\n",
       "      <td>SJ2015150010664</td>\n",
       "      <td>51315201</td>\n",
       "      <td>59.0</td>\n",
       "      <td>M</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>MERIDIAN AV / DOUGLAS ST</td>\n",
       "      <td>LOCAL BENCH WARRANT</td>\n",
       "      <td>TAKEN INTO CUSTODY/WARRANT ARREST ONLY</td>\n",
       "      <td>POSSESSION OF CONTROLLED SUBSTANCE PARAPHERNAL...</td>\n",
       "      <td>4152</td>\n",
       "      <td>BYERS</td>\n",
       "      <td>CHARGED/BOOKED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91122</th>\n",
       "      <td>SJ201530</td>\n",
       "      <td>SJ2015150010664</td>\n",
       "      <td>441729075</td>\n",
       "      <td>59.0</td>\n",
       "      <td>M</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>300 BLOCK MERIDIAN AV</td>\n",
       "      <td>ON VIEW</td>\n",
       "      <td>ON VIEW ARREST</td>\n",
       "      <td>POSSESSION CONTROLLED SUBSTANCE (ONVW)</td>\n",
       "      <td>3773</td>\n",
       "      <td>SOLOMON</td>\n",
       "      <td>CHARGED/BOOKED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65769</th>\n",
       "      <td>SJ201514</td>\n",
       "      <td>SJ2015150010728</td>\n",
       "      <td>441761283</td>\n",
       "      <td>23.0</td>\n",
       "      <td>M</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>HISPANIC/LATIN/MEXICAN</td>\n",
       "      <td>01/01/15</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>5600 BLOCK COTTLE RD</td>\n",
       "      <td>ON VIEW</td>\n",
       "      <td>ON VIEW ARREST</td>\n",
       "      <td>ROBBERY (ONVW)</td>\n",
       "      <td>4240</td>\n",
       "      <td>MORGAN II</td>\n",
       "      <td>CHARGED/BOOKED</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      arrest_unique_id   incident_number        pin   age sex  \\\n",
       "56511         SJ201519   SJ2015150010241  441762891  19.0   M   \n",
       "56522         SJ201519  SJ2015J3347648 C  441762891  19.0   M   \n",
       "51970          SJ20157   SJ2015150010272  441776037  23.0   F   \n",
       "94333        SJ2015190   SJ2015150010482  441915772  33.0   F   \n",
       "94339        SJ2015190  SJ2015J3337366 C  441915772  33.0   F   \n",
       "3262         SJ2015337  SJ2015J3354478 C  441916123  23.0   M   \n",
       "96726         SJ201529   SJ2015150010655  441915179  22.0   M   \n",
       "14755         SJ201525   SJ2015150010664   51315201  59.0   M   \n",
       "91122         SJ201530   SJ2015150010664  441729075  59.0   M   \n",
       "65769         SJ201514   SJ2015150010728  441761283  23.0   M   \n",
       "\n",
       "                         race               ethnicity arrest_date arrest_time  \\\n",
       "56511  HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15       415.0   \n",
       "56522  HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15       415.0   \n",
       "51970  HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15       530.0   \n",
       "94333  HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15      1400.0   \n",
       "94339  HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15      1400.0   \n",
       "3262   HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15      1605.0   \n",
       "96726  HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15      1655.0   \n",
       "14755  HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15      1756.0   \n",
       "91122  HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15      1756.0   \n",
       "65769  HISPANIC/LATIN/MEXICAN  HISPANIC/LATIN/MEXICAN    01/01/15      1831.0   \n",
       "\n",
       "      location_of_arrest_in_block        arrest_reason  \\\n",
       "56511         2900 BLOCK OCALA CT    CRIMINAL CITATION   \n",
       "56522         2900 BLOCK OCALA CT    CRIMINAL CITATION   \n",
       "51970      5100 BLOCK MONTEREY RD              ON VIEW   \n",
       "94333         2200 BLOCK TULLY RD    CRIMINAL CITATION   \n",
       "94339         2200 BLOCK TULLY RD    CRIMINAL CITATION   \n",
       "3262              CURTNER AV / 87    CRIMINAL CITATION   \n",
       "96726        S 1ST ST / W ALMA AV              ON VIEW   \n",
       "14755    MERIDIAN AV / DOUGLAS ST  LOCAL BENCH WARRANT   \n",
       "91122       300 BLOCK MERIDIAN AV              ON VIEW   \n",
       "65769        5600 BLOCK COTTLE RD              ON VIEW   \n",
       "\n",
       "                                  arrest_type  \\\n",
       "56511  TAKEN INTO CUSTODY/WARRANT ARREST ONLY   \n",
       "56522  TAKEN INTO CUSTODY/WARRANT ARREST ONLY   \n",
       "51970                          ON VIEW ARREST   \n",
       "94333  TAKEN INTO CUSTODY/WARRANT ARREST ONLY   \n",
       "94339  TAKEN INTO CUSTODY/WARRANT ARREST ONLY   \n",
       "3262   TAKEN INTO CUSTODY/WARRANT ARREST ONLY   \n",
       "96726                          ON VIEW ARREST   \n",
       "14755  TAKEN INTO CUSTODY/WARRANT ARREST ONLY   \n",
       "91122                          ON VIEW ARREST   \n",
       "65769                          ON VIEW ARREST   \n",
       "\n",
       "                                        summary_of_facts arrest_officer  \\\n",
       "56511                                 TRESPASSING (CITE)           4222   \n",
       "56522                                 TRESPASSING (CITE)           4222   \n",
       "51970            INFLICT CORP INJ ON SPOUSE/COHAB (ONVW)           4348   \n",
       "94333  PETTY THEFT OF PERSONAL PROPERTY/LABOR/EMBEZZL...           3153   \n",
       "94339  PETTY THEFT OF PERSONAL PROPERTY/LABOR/EMBEZZL...           3153   \n",
       "3262   FAILING TO PROVIDE EVIDENCE OF FINANCIAL RESPO...           4280   \n",
       "96726  RESISTING, DELAYING, OBSTRUCTING AN OFFICER (O...           4245   \n",
       "14755  POSSESSION OF CONTROLLED SUBSTANCE PARAPHERNAL...           4152   \n",
       "91122             POSSESSION CONTROLLED SUBSTANCE (ONVW)           3773   \n",
       "65769                                     ROBBERY (ONVW)           4240   \n",
       "\n",
       "      officer_name  current_status young_offender  \n",
       "56511       MACIAS           CITED              N  \n",
       "56522       MACIAS           CITED              N  \n",
       "51970          LEE  CHARGED/BOOKED              N  \n",
       "94333     TOMPKINS           CITED              N  \n",
       "94339     TOMPKINS           CITED              N  \n",
       "3262         ARANA           CITED              N  \n",
       "96726      VALOSEK  CHARGED/BOOKED              N  \n",
       "14755        BYERS  CHARGED/BOOKED              N  \n",
       "91122      SOLOMON  CHARGED/BOOKED              N  \n",
       "65769    MORGAN II  CHARGED/BOOKED              N  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed-dataset.csv\")\n",
    "\n",
    "hispanic_filter = df['race'] == \"HISPANIC/LATIN/MEXICAN\"\n",
    "hispanic_df = df[hispanic_filter].sort_values(by = ['arrest_date', 'arrest_time'], ascending= [True, True])\n",
    "hispanic_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process the Data for Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the fields will be useful to use for the classification task.\n",
    "\n",
    "1. `location_of_arrests_in_block`: Since we're writing a model to predict hotspots, this column is integral to our goal.\n",
    "2. `summary_of_facts`: This column includes a short descrtiption of the arrest, which will provide potentially helpful contextual information to make a better model for our race prediction. We'll see!\n",
    "3. `race`: This column includes information too! Different races of people often capture how demographics are in a certain area. So, the race may also provide potentially helpful contextual information to make a better model. Again, we'll see!\n",
    "\n",
    "The code below creates 3 new columns for that task.\n",
    "\n",
    "There's a lot to unpack below, but it basically\n",
    "\n",
    "2. it creates 3 new columns that are combined with the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153434 entries, 0 to 153433\n",
      "Data columns (total 20 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   arrest_unique_id             153434 non-null  object\n",
      " 1   incident_number              153434 non-null  object\n",
      " 2   pin                          153434 non-null  int64 \n",
      " 3   age                          153434 non-null  object\n",
      " 4   sex                          153434 non-null  object\n",
      " 5   race                         153434 non-null  object\n",
      " 6   ethnicity                    153434 non-null  object\n",
      " 7   arrest_date                  153434 non-null  object\n",
      " 8   arrest_time                  153434 non-null  object\n",
      " 9   location_of_arrest_in_block  153434 non-null  object\n",
      " 10  arrest_reason                153434 non-null  object\n",
      " 11  arrest_type                  153434 non-null  object\n",
      " 12  summary_of_facts             153434 non-null  object\n",
      " 13  arrest_officer               153434 non-null  object\n",
      " 14  officer_name                 153434 non-null  object\n",
      " 15  current_status               153434 non-null  object\n",
      " 16  young_offender               153434 non-null  object\n",
      " 17  arrest_desc                  153434 non-null  object\n",
      " 18  arrest_desc_location         153434 non-null  object\n",
      " 19  arrest_desc_location_race    153434 non-null  object\n",
      "dtypes: int64(1), object(19)\n",
      "memory usage: 23.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#just the description\n",
    "df['arrest_desc'] = df['summary_of_facts']\n",
    "\n",
    "#description + location_of_arrest_in_block\n",
    "df['arrest_desc_location'] = df['summary_of_facts'] + ' '+ df['location_of_arrest_in_block']\n",
    "\n",
    "#description + location_of_arrest_in_block + race\n",
    "df['arrest_desc_location_race'] = df['summary_of_facts'] + ' '+ df['location_of_arrest_in_block']+\" \" + df['race']\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a Logistic Regression Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modeling functions\n",
    "\n",
    "The functions below help us create a systematic and reproducable workflow to train the data.\n",
    "\n",
    "Be sure to check out my videos that walk through an overview of what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reciprocal_rank(true_genre_labels: list, machine_predicted_genre_labels: list):\n",
    "    '''\n",
    "    ## Purpose\n",
    "    Compute the reciprocal rank at cutoff k\n",
    "\n",
    "    ## Parameters\n",
    "        - `true_genre_labels` (List): List of actual news genre labels\n",
    "        - `machine_predicted_genre_labels` (List): List of news genre labels predicted by the LR algorithm\n",
    "    \n",
    "    ## Return Values\n",
    "        - `recip_rank` (Float): Reciprocal rank\n",
    "    '''\n",
    "    \n",
    "    # add index to list only if machine predicted label exists in true labels\n",
    "    tp_pos_list = [(idx + 1) for idx, r in enumerate(machine_predicted_genre_labels) if r in true_genre_labels]\n",
    "\n",
    "    recip_rank = 0\n",
    "    if len(tp_pos_list) > 0:\n",
    "        # for reciprocal rank we must find the position of the first **correctly labeled** item\n",
    "        first_pos_list = tp_pos_list[0]\n",
    "        \n",
    "        # recip_rank = 1/rank\n",
    "        recip_rank = 1 / float(first_pos_list)\n",
    "\n",
    "    return recip_rank\n",
    "\n",
    "def compute_mrr_at_k(eval_news_category_items:list):\n",
    "    '''\n",
    "    ## Purpose\n",
    "    `compute_mrr_at_k()`: Computes the MRR (average RR) at cutoff k. In sum, it takes the mean average of all of the reciprocal rank scores among the actual vs. predicted labels. Review this [\"Mean reciprocal rank\" wikipedia article](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) for a simple explainer.\n",
    "    ## Parameters\n",
    "    - `eval_news_category_items` (List): List that contains 2 values\n",
    "        1. String - Actual news genre category\n",
    "        2. List of strings - Predicted news genre category in order by estimated probability to be returned by the model.\n",
    "            - The example below shows how \n",
    "                - `'HEALTHY LIVING'` was the actual label, but it was third in 'reciprocal rank' with a value of 1/3\n",
    "                - `'WORLDPOST'` was the actual label, and it was first in 'reciprocal rank' with a value of 1\n",
    "                \n",
    "                [\n",
    "                    [\n",
    "                        ['HEALTHY LIVING'], ['POLITICS', 'ENTERTAINMENT', 'HEALTHY LIVING']\n",
    "                    ], \n",
    "                    [\n",
    "                        ['WORLDPOST'], ['WORLDPOST', 'MEDIA', 'POLITICS']\n",
    "                    ], \n",
    "                    ...\n",
    "                ]\n",
    "\n",
    "    ## Return Values\n",
    "        - `mean_reciprocal_rank_score` (Float): Mean average reciprocal rank score among the predicted news category in the model\n",
    "    '''\n",
    "    rr_total = 0\n",
    "    \n",
    "    for item in eval_news_category_items:\n",
    "        actual_label = item[0]\n",
    "        pred_label_list = item[1]\n",
    "\n",
    "        # Find the reciprocal rank (RR) for this row\n",
    "        rr_at_k = _reciprocal_rank(actual_label, pred_label_list)\n",
    "\n",
    "        # Add the row's RR to the accruing scores for the entire corpus\n",
    "        rr_total = rr_total + rr_at_k\n",
    "\n",
    "        # Update the Mean Reciprocal Rank (MRR) score with new row value\n",
    "        mean_reciprocal_rank_score = rr_total / 1/float(len(eval_news_category_items))\n",
    "\n",
    "    return mean_reciprocal_rank_score\n",
    "\n",
    "def collect_preds(Y_test, Y_preds):\n",
    "    '''\n",
    "    ## Purpose\n",
    "    Collect all predictions (predicted news genre labels) and ground truth (i.e., actual news genre label)\n",
    "    '''\n",
    "    pred_gold_list = [ [ [Y_test[index]], pred ] for index, pred in enumerate(Y_preds) ]\n",
    "    return pred_gold_list\n",
    "             \n",
    "def compute_accuracy(eval_news_category_items:list):\n",
    "    '''\n",
    "    ## Purpose\n",
    "    `compute_accuracy()`: Compute the overall accuracy score of the model across the training corpus\n",
    "\n",
    "    ## Parameters\n",
    "        - `eval_news_category_items` (List): List that contains 2 values\n",
    "            1. String - Actual news genre category\n",
    "            2. List of strings - Predicted news genre category\n",
    "\n",
    "            Example: [\n",
    "                [\n",
    "                    ['HEALTHY LIVING'], ['POLITICS', 'ENTERTAINMENT', 'HEALTHY LIVING']\n",
    "                ], \n",
    "                [\n",
    "                    ['WORLDPOST'], ['WORLDPOST', 'MEDIA', 'POLITICS']\n",
    "                ], \n",
    "                ...\n",
    "            ]\n",
    "    ## Return Values\n",
    "        - `news_cat_prediction_accuracy` (Float): Percentage of accurately predicted news category in the model\n",
    "    '''\n",
    "    correct_news_cat = 0\n",
    "    \n",
    "    for news_genre_cat in eval_news_category_items:\n",
    "        true_pred = news_genre_cat[0]\n",
    "        machine_pred = set(news_genre_cat[1])\n",
    "        \n",
    "        for news_cat in true_pred:\n",
    "            if news_cat in machine_pred:\n",
    "                correct_news_cat += 1\n",
    "                break\n",
    "    \n",
    "    news_cat_prediction_accuracy = correct_news_cat / float(len(eval_news_category_items))\n",
    "    return news_cat_prediction_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def extract_features(df, field, training_data, testing_data, type='binary'):\n",
    "    '''\n",
    "    ## Purpose\n",
    "    `extract_features()`: Extract features using different method types: binary, counts, or TF-IDF\n",
    "\n",
    "    ### If BINARY Features\n",
    "    Creates a new `CountVectorizer()` method object, which converts a collection of text documents to a matrix of binary token counts per document. In other words, \n",
    "    - `1` == the feature is represented in the document\n",
    "    - `0` == the feature is not represented in the doc\n",
    "    \n",
    "    Logistic regression involves vectorizing weighted averages of these tokens.\n",
    "\n",
    "    ### If COUNT Features\n",
    "    Creates a new `CountVectorizer()` method object, which converts a collection of text documents to a matrix of `n` token counts per document.  In other words, \n",
    "    - `5` == the feature is represented 5 times in the document\n",
    "    - `25` == the feature is represented 25 times in the document\n",
    "    - `0` == the feature is not represented in the doc\n",
    "    \n",
    "    Logistic regression involves vectorizing weighted averages of these tokens.\n",
    "\n",
    "    ### If TF-IDF Features\n",
    "    Creates a new `CountVectorizer()` method object, which converts a collection of text documents to a matrix of `n` token counts per document.  In other words, \n",
    "    - `5` == the feature is represented 5 times in the document\n",
    "    - `25` == the feature is represented 25 times in the document\n",
    "    - `0` == the feature is not represented in the doc\n",
    "    \n",
    "    Logistic regression involves vectorizing weighted averages of these tokens.\n",
    "    '''\n",
    "    \n",
    "    logging.info(\"Extracting features and creating vocabulary...\")\n",
    "\n",
    "    '''\n",
    "        BINARY and COUNTS PROCESSES WILL DO THE FOLLOWING:\n",
    "\n",
    "        sklearn's CountVectorizer() will convert text to numerical data.\n",
    "    '''\n",
    "    \n",
    "    if 'binary' in type:\n",
    "        \n",
    "        # BINARY FEATURE REPRESENTATION\n",
    "        # Creates a new CountVectorizer() method object, which can help us use built-in functions that convert a collection of text documents to a matrix of token counts. **REMEMBER** that logistic regression involves vectorizing weighted averages of these tokens.\n",
    "        # NOTE: `max_df` == \"Maximum Document Frequency. It enables us to programmatically ignore frequently occuring words, e.g., articles like 'a' or 'the'. `max_df` reviews how many documents contain the word, and if it exceeds the max_df threshold then it is eliminated from the sparse matrix. Below we set the threshold to 95%.\n",
    "        cv = CountVectorizer(binary=True, max_df=0.95)\n",
    "        # CountVectorizer()'s fit_transform() uses the training_data to learn the vocabulary dictionary and return document-term matrix.\n",
    "        cv.fit_transform(training_data[field].values)\n",
    "        # CountVectorizer()'s transform() \n",
    "        train_feature_set = cv.transform(training_data[field].values)\n",
    "        test_feature_set = cv.transform(testing_data[field].values)\n",
    "        \n",
    "        return train_feature_set,test_feature_set,cv\n",
    "  \n",
    "    elif 'counts' in type:\n",
    "        \n",
    "        # COUNT BASED FEATURE REPRESENTATION\n",
    "        cv = CountVectorizer(binary=False, max_df=0.95)\n",
    "        cv.fit_transform(training_data[field].values)\n",
    "        \n",
    "        train_feature_set = cv.transform(training_data[field].values)\n",
    "        test_feature_set = cv.transform(testing_data[field].values)\n",
    "        \n",
    "        return train_feature_set,test_feature_set,cv\n",
    "    \n",
    "    elif 'tfidf':    \n",
    "        \n",
    "        # TF-IDF BASED FEATURE REPRESENTATION\n",
    "        tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "        tfidf_vectorizer.fit_transform(training_data[field].values)\n",
    "        \n",
    "        train_feature_set=tfidf_vectorizer.transform(training_data[field].values)\n",
    "        test_feature_set=tfidf_vectorizer.transform(testing_data[field].values)\n",
    "        \n",
    "        return train_feature_set,test_feature_set,tfidf_vectorizer\n",
    "\n",
    "def get_top_k_predictions(model, X_test, k, threshold=False):\n",
    "    '''\n",
    "    ## Purpose\n",
    "    `get_top_k_predictions()`: Uses the input trained LogisticRegression model to return the news genre class/category with the top estimated probability score.\n",
    "    ## Parameters\n",
    "    - `model` (LogisticRegression()): Trained model scikit-learn object\n",
    "    - `X_test` (pandas DataFrame): Sampled test data set returned by `training_test_split()` in the `training_model()` function\n",
    "    - `k` (Integer): Number of top categories (news genres) to return based on the estimated probability to predict the news genre\n",
    "    ## Return Value(s)\n",
    "    - `preds` (List of list): A list within a list of the top k retruned news categories. For example:\n",
    "        - `preds` is `[['SCIENCE', 'HEALTHY LIVING', 'GREEN']]` for an article with the headline of `\"Exercise in space keeps astronauts from fainting when they return to Earth, study says\"` and `k=3`\n",
    "    '''\n",
    "    if threshold == False:\n",
    "        # get probabilities instead of predicted labels, since we want to collect top 3\n",
    "        probs = model.predict_proba(X_test)\n",
    "\n",
    "        # GET TOP K PREDICTIONS BY PROB - note these are just index\n",
    "        best_n = np.argsort(probs, axis=1)[:,-k:]\n",
    "        \n",
    "        # GET CATEGORY OF PREDICTIONS\n",
    "        preds = [[model.classes_[predicted_cat] for predicted_cat in prediction] for prediction in best_n]\n",
    "        \n",
    "        preds = [ item[::-1] for item in preds]\n",
    "    \n",
    "        return preds\n",
    "    else:\n",
    "        # get probabilities instead of predicted labels, since we want to collect top 3\n",
    "        probs = (model.predict_proba(X_test)[:,1] >= thresh_val)\n",
    "\n",
    "        # GET TOP K PREDICTIONS BY PROB - note these are just index\n",
    "        best_n = np.argsort(probs, axis=1)[:,-k:]\n",
    "        \n",
    "        # GET CATEGORY OF PREDICTIONS\n",
    "        preds = [[model.classes_[predicted_cat] for predicted_cat in prediction] for prediction in best_n]\n",
    "        \n",
    "        preds = [ item[::-1] for item in preds]\n",
    "    \n",
    "        return preds\n",
    "   \n",
    "def train_model(df, field=\"arrest_desc\", feature_rep=\"binary\", top_k=3):\n",
    "    '''\n",
    "    ## Purpose\n",
    "    train_model() is the main controller function that conducts the following modeling procedure: \n",
    "        \n",
    "    1. Create X data (List) by splitting the data to create two sampled sets: 1) for training, and 2) for testing.\n",
    "    2. Create Y data (List) by assigning the actual (ground truth) labels\n",
    "    3. Extract the features for the model to use, based on the chosen feature representation: binary vs. TF-IDF\n",
    "    4. Fit, i.e., train, the logistic regression classifier model with scikit-learn's `LogisticRegression()` object\n",
    "    5. Retrieve the evaluation items, e.g., the actual labels (ground truths) and predicted labels (list of top `k` number of estimated probable predicted categories)\n",
    "    6. Use the evaluation iitems to compute the overall accuracy score and mean reciprocal rank score of the model\n",
    "\n",
    "    ## Parameters\n",
    "    - `df` (pandas DataFrame): the complete data set / corpus\n",
    "    - `field` (String): the column name of the feature used to train the model\n",
    "    - `feature_rep` (String): Type of LR analysis set as either \"binary\" or \"count\" or \"tfidf\"\n",
    "    '''\n",
    "    \n",
    "    logging.info(\"Starting model training...\")\n",
    "    \n",
    "    # 1. GET A TRAIN TEST SPLIT (set seed for consistent results)\n",
    "    # train_test_split() from sklearn \"splits arrays or matrices into random train and test subsets.\"\n",
    "    # returns 2 new dataframes: one for training, another for testing the trained model\n",
    "    y = df['location_of_arrest_in_block']\n",
    "    x_training_data,x_testing_data = train_test_split(\n",
    "        df,\n",
    "        random_state=2000 #Controls the shuffling applied to the data before applying the split\n",
    "    )\n",
    "\n",
    "    # 2. GET LABELS FROM SPLIT DATA\n",
    "    # Get the category values from each split data returned by #1\n",
    "    Y_train = x_training_data['location_of_arrest_in_block'].values\n",
    "    Y_test = x_testing_data['location_of_arrest_in_block'].values\n",
    "     \n",
    "    # 3. GET FEATURES\n",
    "    X_train,X_test,feature_transformer = extract_features(\n",
    "        df,\n",
    "        field,\n",
    "        x_training_data,\n",
    "        x_testing_data,\n",
    "        type=feature_rep\n",
    "    )\n",
    "\n",
    "    # INITIALIZE THE LOGISTIC REGRESSION CLASSIFIER OBJECT\n",
    "    logging.info(\"Training a Logistic Regression Model. This may take a few minutes. ...\")\n",
    "    scikit_log_reg = LogisticRegression(\n",
    "        verbose=0, #if you want the LR method to print out all the details, change this 0 to 1\n",
    "        solver='liblinear',\n",
    "        random_state=0,\n",
    "        C=5,\n",
    "        penalty='l2',\n",
    "        max_iter=1000\n",
    "    )\n",
    "    # Create the model by providing the LR object the \n",
    "    model = scikit_log_reg.fit(X_train, Y_train)\n",
    "\n",
    "    # GET TOP K PREDICTIONS\n",
    "    preds = get_top_k_predictions(model, X_test, top_k)\n",
    "    \n",
    "    # GET PREDICTED VALUES AND GROUND TRUTH INTO A LIST OF LISTS - for ease of evaluation\n",
    "    eval_items = collect_preds(Y_test, preds)\n",
    "    \n",
    "    # GET EVALUATION NUMBERS ON TEST SET -- HOW DID WE DO?\n",
    "    logging.info(\"Starting evaluation...\")\n",
    "    simple_mean_avg_correct_prediction_accuracy = compute_accuracy(eval_items)\n",
    "    mean_recip_rank_at_k = compute_mrr_at_k(eval_items)\n",
    "    \n",
    "    logging.info(\"Done training and evaluation.\")\n",
    "\n",
    "    # Return the herein computed model and other values for potential use and exploration\n",
    "    return model,feature_transformer,simple_mean_avg_correct_prediction_accuracy,mean_recip_rank_at_k,X_train,X_test,Y_test,Y_train,preds,eval_items\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 LR Model 1 - Binary or Count features with `arrest_desc` only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 Enact the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 Test the accuracy/performance of the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.2.1 See the accuracy and Mean Reciprocal Rank Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Overall Mean Average Model Accuracy = {accuracy_td_only}\\nMean Reciprocal Rank = {mrr_at_k_td_only}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ce378d6de975fe6104e21b1d24690891ddd2ffb9a07d282f3dc12a5895daf2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
